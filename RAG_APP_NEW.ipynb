{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1-5pT7XzD0YVTJLcDMOyHmwNXu_NDrFwB",
      "authorship_tag": "ABX9TyN2c6E0HfLV0ex2xEwoQPUF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dharshan4038/PDF_Q-A_USING_RAG/blob/main/RAG_APP_NEW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "gOOTZbfV3WPY"
      },
      "outputs": [],
      "source": [
        "# %pip install langchain ipykernel langchain_community pypdf langchain-text-splitters langchain-openai openai easyocr fitz frontend pymupdf faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install PyMuPDF easyocr pillow langchain"
      ],
      "metadata": {
        "id": "PmWf41kK4U2M"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip uninstall -y PyMuPDF\n",
        "# !pip install PyMuPDF"
      ],
      "metadata": {
        "id": "YJbrlhLp3llp"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip list"
      ],
      "metadata": {
        "id": "9ukXUeAb4SLd"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdf2image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDinxn3o6h0g",
        "outputId": "bbef8bac-b354-442b-a42d-2aba7ddbb465"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pdf2image in /usr/local/lib/python3.10/dist-packages (1.17.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from pdf2image) (9.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz  # PyMuPDF\n",
        "import easyocr\n",
        "import io\n",
        "from PIL import Image\n",
        "from langchain.schema import Document\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings  # Updated for embeddings\n",
        "from langchain_openai import AzureChatOpenAI\n",
        "from langchain_community.document_loaders import PyPDFLoader, TextLoader\n",
        "from langchain_openai import AzureOpenAIEmbeddings"
      ],
      "metadata": {
        "id": "AL4SVo6M6pD3"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract images from PDF\n",
        "def extract_image_from_pdf(pdf_path):\n",
        "    pdf_document = fitz.open(pdf_path)\n",
        "    image_paths = []\n",
        "\n",
        "    for page_num in range(len(pdf_document)):\n",
        "        page = pdf_document.load_page(page_num)\n",
        "        images = page.get_images(full=True)\n",
        "\n",
        "        for image_num, image in enumerate(images):\n",
        "            xref = image[0]\n",
        "            base_image = pdf_document.extract_image(xref)\n",
        "            img_bytes = base_image[\"image\"]\n",
        "            img_pil = Image.open(io.BytesIO(img_bytes))\n",
        "            img_path = f\"/content/drive/MyDrive/output/image_{page_num}_{image_num}.png\"\n",
        "            img_pil.save(img_path)\n",
        "            image_paths.append(img_path)\n",
        "\n",
        "    return image_paths"
      ],
      "metadata": {
        "id": "dL0mU0bk6shg"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract text from images using EasyOCR\n",
        "def extract_text_from_images_easyocr(image_paths):\n",
        "    reader = easyocr.Reader(['en'])\n",
        "    text = \"\"\n",
        "\n",
        "    for image_path in image_paths:\n",
        "        results = reader.readtext(image_path)\n",
        "        for result in results:\n",
        "            text += result[1] + \"\\n\"\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "cmUsGG3c6yUP"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Preprocess the text and create a Document\n",
        "def preprocess_text(text):\n",
        "    lines = text.split(\"\\n\")\n",
        "    for line in lines:\n",
        "        print(line)"
      ],
      "metadata": {
        "id": "yJFwr_K660zd"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load text into Langchain's Document structure\n",
        "def load_image_text_as_document(text):\n",
        "    return Document(page_content=text, metadata={\"source\": \"extracted_images\"})"
      ],
      "metadata": {
        "id": "TsbUMaot63Ho"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split documents into chunks\n",
        "def split_docs(data):\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
        "    return text_splitter.split_documents(data)"
      ],
      "metadata": {
        "id": "v_NPNCJV65SX"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main flow for processing PDF and images\n",
        "def process_pdf_and_images(pdf_path):\n",
        "    # Extract images and text from the PDF\n",
        "    image_paths = extract_image_from_pdf(pdf_path)\n",
        "    text_from_images = extract_text_from_images_easyocr(image_paths)\n",
        "\n",
        "    # Preprocess and create document for image-based text\n",
        "    preprocess_text(text_from_images)\n",
        "    img_doc = load_image_text_as_document(text_from_images)\n",
        "\n",
        "    # Load the PDF content into Langchain's Document format\n",
        "    pdf_loader = PyPDFLoader(pdf_path)\n",
        "    pdf_docs = pdf_loader.load()\n",
        "\n",
        "    # Append the image-based document to the PDF documents\n",
        "    pdf_docs.append(img_doc)\n",
        "\n",
        "    # Split all documents into smaller chunks\n",
        "    split_documents = split_docs(pdf_docs)\n",
        "    return split_documents"
      ],
      "metadata": {
        "id": "5V9qvAAu67lC"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Embedding and Vector Store creation\n",
        "def create_faiss_vector_store(documents):\n",
        "    # Initialize the embedding model\n",
        "    embedding_model =  AzureOpenAIEmbeddings(\n",
        "    azure_endpoint=\"https://llm-api-gateway-v2.azurewebsites.net\",\n",
        "    api_key=\"m8CHxff-D8N3PMQQBINku7JWGRX5JNJUeIDBcym286I\",\n",
        "    model=\"text-embedding-ada-002\",\n",
        "    azure_deployment=\"aiml-interns-embedding-ada-002-model\",\n",
        "  )\n",
        "\n",
        "    # Create a FAISS vector store from the processed documents\n",
        "    vectorstore = FAISS.from_documents(documents, embedding_model)\n",
        "    return vectorstore"
      ],
      "metadata": {
        "id": "Rs2uHmRS6-Vz"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Full execution\n",
        "pdf_path = \"/content/drive/MyDrive/RAG/test_case.pdf\"\n",
        "documents = process_pdf_and_images(pdf_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Y3w7E9O27B6b",
        "outputId": "aff6668a-0a3f-4f66-ca27-f99e25c00532"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
            "/usr/local/lib/python3.10/dist-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ME\n",
            "ME\n",
            "Test Data\n",
            "validity\n",
            "Test Case]\n",
            "Test Casc?\n",
            "Systet\n",
            "Jmntolmat\n",
            "Generation\n",
            "uder\n",
            "Test Casc}\n",
            "Mechanism\n",
            "Test\n",
            "Artifact\n",
            "Test Case n\n",
            "Test\n",
            "Oracle\n",
            "ME\n",
            "ME\n",
            "Need for Literatulre Review\n",
            "Research Questions\n",
            "Planning Phase\n",
            "Review Process\n",
            "Search Criteria\n",
            "Review\" Selection Criteria\n",
            "Conducting Phase\n",
            "Review Selection Procedure\n",
            "Data Extraction\n",
            "Results & Discussion\n",
            "Reporting Phase\n",
            "Conclusion\n",
            "ME\n",
            "ME\n",
            "ME\n",
            "IEEE\n",
            "Sprilger\n",
            "189\n",
            "ACM\n",
            "Fist\n",
            "Second\n",
            "Third\n",
            "Fiwal\n",
            "Elsevier\n",
            "rollnd\n",
            "round\n",
            "rolnd\n",
            "Selection\n",
            "Exclsion\n",
            "Exchsion\n",
            "Exchsion\n",
            "Wiley\n",
            "Google\n",
            "Scholar\n",
            "ME\n",
            "ME\n",
            "ME\n",
            "ME\n",
            "ME\n",
            "ME\n",
            "ME\n",
            "ME\n",
            "ME\n",
            "ME\n",
            "ME\n",
            "ME\n",
            "ME\n",
            "ME\n",
            "ME\n",
            "ME\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore = create_faiss_vector_store(documents)"
      ],
      "metadata": {
        "id": "ErjKsCwW7l-g"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import AzureChatOpenAI\n",
        "import os\n",
        "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"m8CHxff-D8N3PMQQBINku7JWGRX5JNJUeIDBcym286I\"\n",
        "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://llm-api-gateway-v2.azurewebsites.net\""
      ],
      "metadata": {
        "id": "o5UTJK708DLB"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import PyPDFLoader"
      ],
      "metadata": {
        "id": "JounjO4W8IMP"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import  FAISS\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "template = \"\"\"You are an AI assistant for question-answering tasks.\n",
        "        Use the following pieces of context to answer the question. If you don't know the\n",
        "        answer, please output 'No answer'.Use Maximum ten sentence and keep the answer concise\n",
        "        Question: {question} Context: {context}\n",
        "        \"\"\""
      ],
      "metadata": {
        "id": "HdU23G4K8Krq"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "from langchain.chat_models import AzureChatOpenAI\n",
        "from langchain.schema.runnable import  RunnablePassthrough\n",
        "from langchain.schema.output_parser import  StrOutputParser"
      ],
      "metadata": {
        "id": "OBj17TIL8MlA"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_parser = StrOutputParser()"
      ],
      "metadata": {
        "id": "n7nSipmv8PE3"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = AzureChatOpenAI(\n",
        "    azure_endpoint=\"https://llm-api-gateway-v2.azurewebsites.net\",\n",
        "    api_key=\"m8CHxff-D8N3PMQQBINku7JWGRX5JNJUeIDBcym286I\",\n",
        "    model = \"gpt-35-turbo\",\n",
        "    max_tokens=50,\n",
        "    azure_deployment=\"GPT-35-TURBO\",\n",
        "    api_version=\"2024-06-01\"\n",
        ")"
      ],
      "metadata": {
        "id": "UA74xcp08Rlr"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectorstore.as_retriever()"
      ],
      "metadata": {
        "id": "EruOV8sW8Ttp"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "# Create a question-answering chain (QA Chain) that will use the LLM\n",
        "qa_chain = load_qa_chain(llm, chain_type=\"stuff\", prompt=prompt)\n",
        "\n",
        "# Define the ConversationalRetrievalChain to structure the pipeline\n",
        "chain = ConversationalRetrievalChain.from_llm(\n",
        "    llm=llm,\n",
        "    retriever=retriever,\n",
        "    return_source_documents=True\n",
        ")"
      ],
      "metadata": {
        "id": "m2qcOGeV8WRv"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example question\n",
        "question = \"What is the percentage of publication in conference in public distribution ?\"\n",
        "\n",
        "# Initialize an empty chat history\n",
        "chat_history = []\n",
        "\n",
        "# Invoke the chain\n",
        "try:\n",
        "    response = chain({\"question\": question, \"chat_history\": chat_history})\n",
        "    answer = response[\"answer\"]\n",
        "    source_documents = response[\"source_documents\"]\n",
        "\n",
        "    print(\"Answer:\", answer)\n",
        "    print(\"Source Documents:\", source_documents)\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q26ElGPO8ZYA",
        "outputId": "b76a6dc1-a5d1-42ca-ecb9-86dcdf810ed1"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: The percentage of publication in conferences in the publication distribution is 21%.\n",
            "Source Documents: [Document(metadata={'source': '/content/drive/MyDrive/RAG/test_case.pdf', 'page': 8}, page_content='Figure 7. Publication distribution . \\nPublication in \\nConference\\n21%\\nPublication in \\nJournal\\n79%Publication Distribution\\nPublication in Conference Publication in Journal'), Document(metadata={'source': '/content/drive/MyDrive/RAG/test_case.pdf', 'page': 8}, page_content='2020  Mocha JS, \\nNode JS  “Implementing DDD for Automatic Test Case Generation”  (Nachiengmai et al., \\n2020)  \\n \\n \\nAnswer to RQ 3 \\nThe classification of research papers may help in tracking the research growth of the domain. The ratio \\namongst the papers  published in conferences and journals of repute may give a clear idea about the \\ngrowth. To provide the answer t o RQ 3, authors have classified the research papers in these two classes.  \\n \\nFigure 7 depict s that out of 1 25 selected papers, 79% papers come from journal publication and 21% \\npapers have been published in conference publication. The ratio of publication indicates that from year \\n2011 to 2021 maximum papers of test case generation published in a variety of journals.  The lists of fe w \\npapers with publication details are  mentioned in the T able 8 that may help to the beginner’s  level \\nresearchers to explore the important literature . \\n \\n \\n \\n \\nFigure 7. Publication distribution . \\nPublication in \\nConference\\n21%'), Document(metadata={'source': '/content/drive/MyDrive/RAG/test_case.pdf', 'page': 3}, page_content='research?  \\nRQ3: What is the ratio of publishing research articles in conferences and journals  of repute  on test case \\ngeneration ? \\nRQ4: Which type of testing has been explored a lot for research of test case generation?  \\nRQ5: What are  the various tools developed and utilize d for automatic test case generation?  \\nRQ6: What are the various optimization algorithms used for optimizing the results of test case generation  \\nprocess ?'), Document(metadata={'source': '/content/drive/MyDrive/RAG/test_case.pdf', 'page': 5}, page_content='Total Publications = 125\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n Define search string as \\nkeywords  \\nExecute/ Start search using \\ndifferent online databases  \\nInclude all papers with \\nrelevant headings & \\nobjective of study  \\nRemove all  papers whose \\nheadings have not  fulfilled \\nthe objective of study  \\nRemove  such papers whose \\nabstract & conclusion are \\nnot relevant as per study  \\nComplete Review Paper \\nwith appropriate data')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Name me the Input Language of testing tool used in test case genration in year of development/modification 2013 ?\"\n",
        "\n",
        "# Initialize an empty chat history\n",
        "chat_history = []\n",
        "\n",
        "# Invoke the chain\n",
        "try:\n",
        "    response = chain({\"question\": question, \"chat_history\": chat_history})\n",
        "    answer = response[\"answer\"]\n",
        "    source_documents = response[\"source_documents\"]\n",
        "\n",
        "    print(\"Answer:\", answer)\n",
        "    print(\"Source Documents:\", source_documents)\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0fTb4Nz8h2p",
        "outputId": "9b9bf4ab-14b6-4aec-a668-c177671751b7"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: The input language of the testing tool used in test case generation in the year 2013 is C Language.\n",
            "Source Documents: [Document(metadata={'source': '/content/drive/MyDrive/RAG/test_case.pdf', 'page': 9}, page_content='Year of \\nDevelopment/ \\nModification  Name of Tool  Input Language  Type of Software  Reference  \\n2010  Austin  C Language   Open Source  (Lakhotia et al., 2010)  \\n2010  PET Java Academic & Research  (Albert et al., 2010)  \\n2011  Korat  Java Open Source  (Boyapati et al., 2002)  \\n2011  jPET  Java Commercial  (Albert et al., 2011)  \\n2012  Palus  Java Open Source  (Zhang et al., 2011)  \\n2013  MergePoint/ Mayhem  binary (32bit, Linux)  Commercial  (Avgerinos et al., 2014)  \\nSoftware \\nTesting\\n74%Evolutionary \\nTesting\\n2%Regression \\nTesting\\n13%Others\\n9%AI Testing\\n2%RESEARCH DISTRIBUTION IN TESTING TYPE'), Document(metadata={'source': '/content/drive/MyDrive/RAG/test_case.pdf', 'page': 10}, page_content='Verma et al.: Software Test Case Generation Tools and Techniques: A Review  \\n \\n \\n303 | Vol. 8, No. 2, 202 3 \\nTable 6 continued…  \\n \\n2013  PathCrawler  C Language  Academic & Research  (Williams et al., 2005)  \\n2014  CREST  C Language  Open Source  (Boshernitsan et al., \\n2006)  \\n2014  CAUT  C Language  Academic & Research  (Su et al., 2015)  \\n2014  Jseft JavaScript  Academic & Open Source  (Mirshokraie et al., 2015)  \\n2015  AgitarOne  Java Commercial  (Burnim and Sen, 2008)  \\n2015  AutoTest  Eiffel  Commercial & Open \\nSource  (Leitneret al., 2007 ) \\n2015  CATG  Java Open Source  (Tanno et a l., 2015)  \\n2015  EvoSuite  Java Academic & Open Source  (Fraser and Arcuri, 2013)  \\n2016  GRT  Java Academic & Research  (Ma et al., 2016)  \\n2015  GUITAR  GUI application  Open Source  (Nguyen et al., 2014)  \\n2015  Jalangi  JavaScript   Open Source  (Kalasapur et al., 2013)  \\n2015  JTExpert  Java Academic & Research  (Sakti et al., 2015)  \\n2015  Randoop  Java  Open Source  (Pacheco et al., 2007)'), Document(metadata={'source': '/content/drive/MyDrive/RAG/test_case.pdf', 'page': 9}, page_content='Figure 8. Research Distribution including various testing do main . \\n \\n \\nAnswer to RQ 5 \\nAccording to literature, various testing tools have been developed to address the challenges of test case \\ngeneration. In order to fulfill the requirements and maintain the quality of the software, researchers have \\ndeveloped  a variety of tools  for generatin g new test cases for existing/ new software.  To answer the RQ5, \\nTable 6  has been formed from the literature that list the various testing tools utilized for automatic \\ngeneration of test cases. In Table 6 , 24 different tools are mentioned which represent t he name of tool, \\ninput language used by tool, the category of tool and short description as well as year of development/ \\nmodification of tool.  \\n \\nTable 6 . List of various testing tools used in test case generation . \\n \\nYear of \\nDevelopment/ \\nModification  Name of Tool  Input Language  Type of Software  Reference'), Document(metadata={'source': '/content/drive/MyDrive/RAG/test_case.pdf', 'page': 17}, page_content='Verma et al.: Software Test Case Generation Tools and Techniques: A Review  \\n \\n \\n310 | Vol. 8, No. 2, 202 3 \\nHui, Z.W., & Huang, S. (2013, December). Achievements and challenges of metamorphic testing. In  2013 Fourth \\nWorld Congress on Software Engineering  (pp. 73 -77). IEEE. Hong Kong, China . \\nIqbal, N., Zafar, K., & Zyad, W. (2014, April). Multi -objective optimization of test sequence generation using multi -\\nobjective firefly algorithm (MOFA). In  2014 International Conference on Robotics and Emerging Allied \\nTechnologies in Engineering (iCREATE)  (pp. 214 -220). IEEE. Islamabad, Pakistan.  \\nJatana, N., & Suri, B. (2020). An i mproved crow search algorithm for test data generation using search -based \\nmutation testing.  Neural Processing Letters , 52(1), 767 -784. \\nKhari, M. (2020). Empirical evaluation of automated test suite generation and optimization.  Arabian Journal for \\nScience a nd Engineering , 45(4), 2407 -2423. https://doi.org/10.1007/s13369 -019-03996 -3.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Name me the Title of the paper of dataset utilized in test case genration in year of publication 2015?\"\n",
        "\n",
        "# Initialize an empty chat history\n",
        "chat_history = []\n",
        "\n",
        "# Invoke the chain\n",
        "try:\n",
        "    response = chain({\"question\": question, \"chat_history\": chat_history})\n",
        "    answer = response[\"answer\"]\n",
        "    source_documents = response[\"source_documents\"]\n",
        "\n",
        "    print(\"Answer:\", answer)\n",
        "    print(\"Source Documents:\", source_documents)\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsF8wIfF9NyT",
        "outputId": "c34324f7-ee8e-46e3-9831-659a12475f7a"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: The title of the paper utilizing the dataset \"EvoSuite 10\" in the year of publication 2015 is \"A Memetic Algorithm for whole test suite generation\" (Fraser et al., 2015).\n",
            "Source Documents: [Document(metadata={'source': '/content/drive/MyDrive/RAG/test_case.pdf', 'page': 12}, page_content='2016  Software \\nTesting  Test Case \\nGeneration  Toy Dataset  paper proposed a methodology \\nfor generating test cases  Journal  (Sahoo et al., 2016b)'), Document(metadata={'source': '/content/drive/MyDrive/RAG/test_case.pdf', 'page': 12}, page_content='Generation  No Dataset  Survey/Review  Journal  (Pahwa and Solanki, \\n2014)  \\n2014  Software \\nTesting  Test Suite \\nGeneration  No Dataset  Survey/Review  Journal  (Hooda and Chhillar, \\n2014)  \\n2015  Evolutionary \\nTesting  Test Suite \\nGeneration  EvoSuite 10 tool  Memetic Algorithm for test \\nsuite  optimization  Journal  (Fraser et al., 2015)  \\n2016  Software \\nTesting  Test Case \\nGeneration  Toy Dataset  proposed a methodology for \\ngenerating test cases  Journal (Sahoo et al., 2016 a) \\n2016  Software \\nTesting  Test Case \\nGeneration  Toy Dataset  proposed an approach  Journal  (Sahoo et al., 2016)   \\n2016  Software \\nTesting  Test Case \\nGeneration  overview of \\ndifferent techniques \\nof automatic test \\ncases generation  Survey/ Review  Journal  (Mahadik et al., \\n2016)  \\n2016  Software \\nTesting  Test Case \\nGeneration  Toy Dataset  Proposed an optimization \\napproach  Journal  (Mateen et al., 2016)  \\n2016  Software \\nTesting  Test Case \\nGeneration  Toy Dataset  paper proposed a methodology'), Document(metadata={'source': '/content/drive/MyDrive/RAG/test_case.pdf', 'page': 13}, page_content='2018  Software \\nTesting  Test Cases \\nGeneration  Toy dataset  proposed a new approach  Conference  (Din and Zamli, 2018)  \\n2019  Regression \\nTesting  Test Suite \\nGeneration  five Java \\nprograms under \\ntest performance evaluation of six \\nmeta - heuristic algorithms  Journal  (Khari et al., 2020)  \\n2019  Software \\nTesting  Test Case \\nGeneration  Toy Dataset  present a model -based \\napproach  Journal  (Yazdani Seqerloo et \\nal., 2019)  \\n2019  Software \\nTesting  Test Case \\nGeneration  No Dataset  Survey Paper  Journal  (Khari and Kumar, \\n2019)  \\n2019  Software \\nTesting  Test Case \\nGeneration  Toy Dataset  proposed an automatic \\napproach  Journal  (Alrawashed et al., \\n2019)  \\n2019  Software \\nTesting  Test Case \\nGeneration  No Dataset  review  Journal  (Gupta et al., 2019)  \\n2019  Software \\nTesting  Test Case \\nGeneration  Toy dataset  proposed a method for \\ndemand -based TCG for OO \\nsystems  Journal  (Singh et al., 2019)  \\n2019  Regression \\nTesting  Test Case'), Document(metadata={'source': '/content/drive/MyDrive/RAG/test_case.pdf', 'page': 8}, page_content='Verma et al.: Software Test Case Generation Tools and Techniques: A Review  \\n \\n \\n301 | Vol. 8, No. 2, 202 3 \\nAnswer to RQ2  \\nDuring  the review processes  it becomes clear that many of researchers have utilized various standard \\ndatasets and sample programs to validate their test cas e generation approaches. Table 5  shows the brief \\ndetails of dataset utilized in Test Case Generation.  \\n \\nTable 5 . Details of dataset utilized in test case generation.  \\n \\nYear of \\nPublicatio\\nn Dataset \\nutilized  Title of Paper  Reference  \\n2015  EvoSuite 10  “A Memetic Algorithm for whole test suite generation”  (Fraser et al., 2015)  \\n2017  SF100 corpus  “A detailed investigation of the effectiveness of whole test suite generation”  (Rojas et al., 2017)  \\n2017  Defects4J \\nrepository  “Test Case Generation for Program Repair: A Study of Feasibility and \\nEffectiveness”  (Yu et al., 2017)  \\n2020  Neo4j, JSON  “Test case generation based on mutations over user execution traces”  (Paiva et al., 2020)')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "edk49Y7hB2uc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}